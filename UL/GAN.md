# GAN 정리


## GAN이란?


> *GAN의 주요 아이디어는 예술 작품 위조와 비슷하다.  
> 즉, 작가가 더 유명한 다른 예술가의 예술작품을 위조하는 과정과 비슷하다.*  



GAN은 다음 그림처럼 두 개의 신경망을 동시에 훈련한다. 
생성기generator G(Z)는 작품을 위조하고 판별기discriminator D(Y)는 관찰한 진짜 작품에 기반을 두고 위조한 작품이 얼마나 진짜 같은지를 판단한다. 
D(Y)는 입력으로 Y(예를 들어 하나의 이미지)를 받아 입력 변수가 얼마나 진짜 같은지를 판단하고자 투표한다. 
일반적으로 1에 가까운 값은 ‘진짜’를 나타내고 0에 가까운 값은 ‘위조’를 나타낸다. 

G(Z)는 랜덤 노이즈 Z에서 입력을 받아 G(Z)가 생성하는 모든 것이 실제라고 생각하게 D를 속이도록 훈련한다. 
판별기 D(Y)의 훈련 목적은 참 데이터 분포에서 모든 이미지의 D(Y)는 최대화하고 참 데이터 분포에서 나온 것이 아닌 모든 이미지의 D(Y)는 최소화하는 것이다. 
따라서 G와 D는 반대 게임을 한다. 따라서 적대적 훈련adversarial training이라는 이름이 생겼다. 
여기서 G와 D는 교대로 훈련하고, G와 D 각각의 목표는 그래디언트 하강을 통해 최적화된 손실 함수로 표현된다. 

생성 모델은 지속적으로 위변조 능력을 향상시키고, 판별 모델은 위변조 인식 기능을 계속 향상시킨다. 
판별기 신경망(일반적으로 표준 컨볼루션 신경망)은 입력 이미지가 실제인지 아니면 생성된 것인지를 분류하려 한다. 
중요한 새 아이디어는 생성자가 판별기를 더 자주 속일 수 있는 방법을 학습할 수 있도록 생성기와 그 판별기 모두에게 역전파해 생성기의 매개 변수를 조정하는 것이다. 
마지막으로 생성기는 실제 이미지와 구별할 수 없는 이미지를 생성하는 방법을 학습한다. 

![그림 1 랜덤 노이즈 Z를 입력 변수로 사용할 때 생성기와 판별기의 훈련 흐름](https://user-images.githubusercontent.com/42468263/186198569-bd72f732-af2b-479f-a93a-f7cc6084eb8f.png)


물론 GAN은 두 명의 경기자가 참여한 게임에서 평형equilibrium을 이루고자 노력한다. 
여기서 평형이 무슨 의미인지 먼저 이해할 필요가 있다. 시작 시점에서 두 선수 중 하나는 다른 선수보다 더 잘하길 바란다. 
그럴 경우 다른 쪽을 향상시키게 되고, 이런 방식으로 생성기와 판별기는 서로를 향상시키게 된다. 궁극적으로 어느 한쪽도 더 이상 눈에 띄게 발전하지 않는 상태에 도달하게 된다. 

손실 함수를 도식화해 두 손실(그래디언트 손실과 판별기 손실)이 언제 정점에 도달하는지 보고 이를 확인한다. 우리는 게임이 한 방향으로 너무 치우치기를 원치 않는다. 


> *위조범이 모든 경우에 판사를 속이는 방법을 즉시 배운다면 위조범은 더 이상 배울 것이 없다.*



GAN의 수렴과 다른 종류의 GAN의 안정성에 대한 세부 사항 참고 링크 : [Convergence and Stability of GAN training](https://avg.is.tuebingen.mpg.de/projects/convergence-and-stability-of-gan-training)

GAN의 생성적 응용에서는 생성기가 판별기보다 좀 더 잘 학습하기를 원한다. 

이제 GAN 학습 방법을 자세히 알아보자. 판별기와 생성기는 모두 교대로 학습한다. 학습은 두 단계로 나눌 수 있다. 

1. 여기서는 판별기 D(x)가 학습한다. 생성기 G(z)는 랜덤 노이즈 z(이는 어떤 사이즈 분포 P(z)를 따른다)에서 가짜 이미지를 생성하는 데 사용된다. 
생성기가 만든 가짜 이미지와 훈련 데이터셋의 진짜 이미지는 모두 판별기로 전달되고, 판별기는 지도학습을 통해 가짜와 진짜를 구분하려 학습한다. 
P 데이터 (x)가 훈련 데이터셋 분포라면 판별기 신경망은 해당 목적 함수를 최대화 해 입력 데이터가 진짜일 때는 1에 가깝게, 입력 데이터가 가짜일 때는 0에 가깝게 하려 한다. 
2. 다음 단계에서는 생성기 신경망이 학습한다. 생성기의 목표는 판별기 신경망이 생성된 G(z)가 진짜인 것으로 생각하게끔 속이는 것이다. 즉, D(G(z))를 1에 가깝게 하려 한다.

두 단계는 순차적으로 반복된다. 일단 훈련이 종료되면 판별기는 더 이상 실제 데이터와 가짜 데이터를 구별할 수 없고 생성기는 훈련 데이터와 매우 유사한 데이터를 작성하는 전문가가 된다.
