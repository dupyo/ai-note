# 배치 사이즈(Batch size), 에포크(Epoch), 반복(Iteration)

딥러닝을 공부하다보면 접하는 단어들이 있는데, 그 중에서 배치 사이즈(Batch size)와 에포크(Epoch), 반복(Iteration)이 뭔지 알아본다.

<hr/>

**1. 배치 사이즈(Batch size)**
   - 트레이닝 데이터 셋을 여러 개의 그룹으로 쪼개는데 각각의 그룹을 미니 배치라고 하며, Batch size란 그룹에 속한 데이터의 수를 의미함.

**2. 에포크(Epoch)**
   - Epoch란 전체 트레이닝 셋이 신경망을 통과하는 횟수를 말함.

**3. 반복(Iteration)**
   - 반복(Iteration)은 1 Epoch를 마치는데 필요한 트레이닝 셋을 구성하는 미니 배치의 수를 의미함.

